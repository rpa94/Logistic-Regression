{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_RA18jE5HgC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Questions:\n",
        "\n",
        "\n",
        "\n",
        "Theoretical:\n",
        "\n",
        "\n",
        "\n",
        "Qu.1 What is Logistic Regression, and how does it differ from Linear Regression\n",
        "\n",
        "\n",
        "Ans.  Logistic Regression is a statistical method used for binary classification problems. It predicts the probability of an outcome belonging to a particular category, typically represented as 0 or 1.\n",
        "\n",
        "Differences from Linear Regression:\n",
        "\n",
        "1. output Type:\n",
        "\n",
        "* Linear Regression predicts continuous values.\n",
        "\n",
        "* Logistic Regression predicts probabilities and classifies data into discrete categories (0 or 1).\n",
        "\n",
        "2. Function Used:\n",
        "\n",
        "* Linear Regression uses a linear function: ( y = \\beta_0 + \\beta_1x )\n",
        "\n",
        "* Logistic Regression applies a Sigmoid function to convert the output into a probability.\n",
        "\n",
        "3. Interpretation:\n",
        "\n",
        "* Linear Regression finds the best fit line.\n",
        "\n",
        "* Logistic Regression finds a decision boundary to separate classes.\n",
        "\n",
        "\n",
        "Qu.2  What is the mathematical equation of Logistic Regression\n",
        "\n",
        "Ans. The equation of Logistic Regression is:\n",
        "\n",
        "[ P(Y=1 | X) = \\frac{1}{1 + e^{- (\\beta_0 + \\beta_1X)}} ]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( P(Y=1 | X) ) is the probability that output is 1.\n",
        "\n",
        "* ( \\beta_0, \\beta_1 ) are the model coefficients.\n",
        "\n",
        "* ( X ) is the input variable.\n",
        "\n",
        "* The Sigmoid function is used to map the output between 0 and 1.\n",
        "\n",
        "\n",
        "\n",
        "Qu.3 Why do we use the Sigmoid function in Logistic Regression\n",
        "\n",
        "Ans.The Sigmoid function converts any real-valued number into a probability between 0 and 1:\n",
        "\n",
        "[ sigmoid(z) = \\frac{1}{1 + e^{-z}} ]\n",
        "\n",
        "Reasons for using Sigmoid:\n",
        "\n",
        "* Probability Interpretation: The output is always between 0 and 1, making it suitable for classification.\n",
        "\n",
        "* Non-linearity: Helps model complex relationships.\n",
        "\n",
        "* Decision Boundary: Classifies data based on a probability threshold (e.g., 0.5).\n",
        "\n",
        "Que.4  What is the cost function of Logistic Regression\n",
        "\n",
        "Ans.The log loss function (Binary Cross-Entropy Loss) is used:\n",
        "\n",
        "[ J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(h_\\theta(x_i)) + (1 - y_i) \\log(1 - h_\\theta(x_i)) \\right] ]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( y_i ) is the actual label (0 or 1).\n",
        "\n",
        "* ( h_\\theta(x_i) ) is the predicted probability.\n",
        "\n",
        "* ( m ) is the number of observations.\n",
        "\n",
        "This function penalizes incorrect predictions, ensuring that the model minimizes error.\n",
        "\n",
        "Qu.  What is Regularization in Logistic Regression? Why is it needed\n",
        "\n",
        "Ans.Regularization is a crucial technique in machine learning used to prevent overfitting by adding a penalty term to the model's objective function during training.\n",
        "\n",
        "\n",
        "Types of Regularization:\n",
        "\n",
        "* L1 Regularization (Lasso): Adds the absolute value of coefficients.\n",
        "\n",
        "* L2 Regularization (Ridge): Adds the squared value of coefficients.\n",
        "\n",
        "Why is it needed?\n",
        "\n",
        "* Prevents the model from memorizing noise.\n",
        "* Reduces model complexity.\n",
        "* Improves generalization on unseen data.\n",
        "\n",
        "\n",
        "Qu.6  Explain the difference between Lasso, Ridge, and Elastic Net regression\n",
        "\n",
        "\n",
        "Ans.Comparing Ridge, Lasso Regression, and Elastic Net:\n",
        "\n",
        "\n",
        "* Ridge regression can very effectively reduce the impact of multicollinearity and stabilize coefficient estimates, while it typically will not end up with exact zero coefficients that tallied-off each other in underdetermined cases.\n",
        "\n",
        "* Lasso regression also actually includes a procedure for variable selection. It can set the tuned parameters down to zero thereof contents became more sparse in feature space.\n",
        "\n",
        "* Elastic Net is a combination of Ridge and Lasso, giving us a generalization on the benefits both. It has been developed to take account of trade-offs between coefficient shrinkage and sparsity control.\n",
        "\n",
        "\n",
        "Qu.7  When should we use Elastic Net instead of Lasso or Ridg\n",
        "\n",
        "\n",
        "Ans.Elastic Net regression is a versatile approach that effectively deals with both multicollinearity and feature selection and so is especially appropriate for datasets where both multicollinearity and sparse predictors feature simultaneously.\n",
        "\n",
        "\n",
        "Qu.8  What is the impact of the regularization parameter (λ) in Logistic Regression\n",
        "\n",
        "Ans.  * Higher λ → More regularization → Smaller coefficients → Simpler model.\n",
        "\n",
        "* Lower λ → Less regularization → More complex model.\n",
        "\n",
        "* Too high λ → Underfitting.\n",
        "\n",
        "* Too low λ → Overfitting.\n",
        "\n",
        "\n",
        "Que.9  What are the key assumptions of Logistic Regression\n",
        "\n",
        "Ans.  * Independent observations – No multicollinearity among predictors.\n",
        "\n",
        "* Linearity in log-odds – Relationship between features and log-odds is linear.\n",
        "\n",
        "* No missing values – Data should be complete.\n",
        "\n",
        "\n",
        "\n",
        "Qu.10  What are some alternatives to Logistic Regression for classification tasks\n",
        "\n",
        "\n",
        "Ans. * Decision Trees\n",
        "\n",
        "* Random Forest\n",
        "\n",
        "* Support Vector Machines (SVM)\n",
        "\n",
        "* Neural Networks\n",
        "\n",
        "* Naïve Bayes\n",
        "\n",
        "\n",
        "Qu.11 What are Classification Evaluation Metrics\n",
        "\n",
        "Ans.  * Accuracy\n",
        "\n",
        "* Precision, Recall, F1-score\n",
        "\n",
        "* ROC-AUC Curve\n",
        "\n",
        "* Confusion Matrix\n",
        "\n",
        "\n",
        "Qu.12  How does class imbalance affect Logistic Regression\n",
        "\n",
        "Ans. Leads to biased predictions towards the majority class.\n",
        "\n",
        "Solutions: SMOTE, Class weights adjustment, Threshold tuning.\n",
        "\n",
        "\n",
        "Qu.13  What is Hyperparameter Tuning in Logistic Regression\n",
        "\n",
        "\n",
        "Ans.  Adjusting parameters like regularization strength (λ) and solver to improve performance.\n",
        "Done using GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "\n",
        "Qu.14  What are different solvers in Logistic Regression? Which one should be used\n",
        "\n",
        "\n",
        "Ans. solvers:\n",
        "\n",
        "*  Liblinear Solver:\n",
        "  This solver is efficient for small to medium-sized datasets and is known for its ability to handle L1 and L2 regularization. It supports both binary and multi-class classification.\n",
        "\n",
        "\n",
        "\n",
        "*  SAG Solver:\n",
        " The Saga solver is recommended when dealing with large-scale datasets and when feature sparsity is a concern.\n",
        "\n",
        "\n",
        " * Newton-CG Solver:\n",
        " It is suitable for problems with a large number of features and can handle both L1 and L2 regularization.\n",
        "\n",
        "\n",
        " * LBFGS Solver:\n",
        "      Limited-memory Broyden-Fletcher-Goldfarb-Shanno\n",
        "\n",
        "       It is suitable for problems with a large number of features and supports both L1 and L2 regularization.\n",
        "\n",
        "Qu.15  How is Logistic Regression extended for multiclass classification\n",
        "\n",
        "\n",
        "Ans. * One-vs-Rest (OvR) – Trains one model per class.\n",
        "\n",
        "* Softmax Regression (Multinomial) – Generalizes Logistic Regression for multiple classes.\n",
        "\n",
        "\n",
        "Qu.16  What are the advantages and disadvantages of Logistic Regression\n",
        "\n",
        "\n",
        "Ans. Advantages:\n",
        "\n",
        "* Ease of Implementation and Interpretation\n",
        "\n",
        "* No Assumptions About Class Distributions\n",
        "\n",
        "* Multiclass Extension\n",
        "\n",
        "* Probabilistic Interpretation\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "* Linearity Assumption\n",
        "\n",
        "* Overfitting in High Dimensions\n",
        "\n",
        "* Limited to Binary and Discrete Outcomes\n",
        "\n",
        "* Multicollinearity\n",
        "\n",
        "* Large Dataset Requirement\n",
        "\n",
        "* Difficulty in Capturing Complex Relationships\n",
        "\n",
        "\n",
        "Qu.17  What are some use cases of Logistic Regression\n",
        "\n",
        "Ans * Spam detection\n",
        "\n",
        "* Medical diagnosis (e.g., cancer detection)\n",
        "\n",
        "* Credit scoring\n",
        "\n",
        "Qu.18  What is the difference between Softmax Regression and Logistic Regression\n",
        "\n",
        "\n",
        "Ans. Logistic Regression: Used for binary classification.\n",
        "\n",
        "Softmax Regression: Used for multiclass classification.\n",
        "\n",
        "Qu.19  How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification\n",
        "\n",
        "Ans.*  OvR: Suitable for unbalanced data.\n",
        "\n",
        "* Softmax: Preferred for balanced datasets.\n",
        "\n",
        "Qu.20  How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "\n",
        "Ans.* Positive coefficient: Increases probability of class 1.\n",
        "\n",
        "* Negative coefficient: Decreases probability of class 1.\n",
        "\n",
        "* Magnitude: Larger values have a stronger impact.\n",
        "\n",
        "\n",
        "Practical Questions:\n",
        "\n",
        "Qu.1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "Regression, and prints the model accuracy.\n",
        "'''"
      ],
      "metadata": {
        "id": "2brs1ySo5Rjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itSCCj_FwzNY",
        "outputId": "24068993-2981-4468-b527-932e150acfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Write a Python program to apply L1 regularization (Lasso) on a dataset using\n",
        "and print the model accuracy.\n",
        "'''"
      ],
      "metadata": {
        "id": "9n5XiuBrx_3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with L1 regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L1 regularization (Lasso): {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ca7DgblwzKT",
        "outputId": "7a95fdcf-0694-4a89-d397-2a40552d7b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 regularization (Lasso): 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "UF35pyndyQwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with L2 regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L2 regularization (Ridge): {accuracy:.2f}')\n",
        "\n",
        "# Print the model coefficients\n",
        "print('Model Coefficients:')\n",
        "print(model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK29DzTuyWE9",
        "outputId": "22266350-4dcb-436e-a2d5-1c9d0bab75fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 regularization (Ridge): 0.97\n",
            "Model Coefficients:\n",
            "[[-4.70615403e-01  6.52347878e-01  1.15785115e+00 -5.93993010e-01\n",
            "  -2.40022883e-02  1.22893881e-01  1.34792635e+00  1.21129324e-01\n",
            "  -3.06785207e-01 -7.98211199e-02 -1.51671077e-01  7.16849518e-01\n",
            "   1.41153991e-02]\n",
            " [ 8.05008463e-01 -1.09848709e+00 -8.53071213e-01  2.77643511e-01\n",
            "   2.95994782e-03  6.31536994e-02  4.73150900e-01  2.72080075e-01\n",
            "   6.91066585e-01 -1.78399154e+00  6.66507852e-01  3.35794615e-01\n",
            "  -1.20384315e-02]\n",
            " [-2.59133933e-01  6.52310178e-01  1.20611740e-01  8.04321893e-02\n",
            "   1.92407496e-02 -5.19182381e-01 -1.70239118e+00 -1.24123949e-01\n",
            "  -7.08593522e-01  1.03220422e+00 -4.64782174e-01 -1.23780486e+00\n",
            "  -5.56613331e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')"
      ],
      "metadata": {
        "id": "O-3Wyux9ycTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with Elastic Net Regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with Elastic Net Regularization: {accuracy:.2f}')\n",
        "\n",
        "# Print the model coefficients\n",
        "print('Model Coefficients:')\n",
        "print(model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msuZ8KKCyjvT",
        "outputId": "43484562-dec8-4e03-e9b6-61e876c0f3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 0.75\n",
            "Model Coefficients:\n",
            "[[-6.18596693e-03 -1.94560904e-03 -1.09971694e-03 -1.59478335e-02\n",
            "  -3.81562680e-02 -1.83082269e-04  8.68812461e-04 -3.19806361e-04\n",
            "  -2.09520377e-04 -3.15096917e-03 -2.79198948e-04 -1.53178074e-04\n",
            "   5.68135829e-03]\n",
            " [ 3.96371057e-03 -1.13367311e-03  5.93425897e-04  9.80101595e-03\n",
            "   2.99267969e-02  1.54838807e-03  2.26278716e-03  3.10925815e-05\n",
            "   1.26390405e-03 -5.43751990e-03  1.00216509e-03  2.70097794e-03\n",
            "  -4.43096511e-03]\n",
            " [ 2.18067877e-03  3.10626068e-03  4.64707601e-04  6.10525755e-03\n",
            "   8.18789942e-03 -1.32372236e-03 -3.17238048e-03  2.47153765e-04\n",
            "  -1.01280023e-03  8.63007829e-03 -6.81382694e-04 -2.50621642e-03\n",
            "  -1.20915538e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "multi_class='ovr'."
      ],
      "metadata": {
        "id": "LQ1VKD8TyrMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression for multiclass classification using one-vs-rest (ovr)\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with multi_class=\"ovr\": {accuracy:.2f}')\n",
        "\n",
        "# Print the model coefficients\n",
        "print('Model Coefficients:')\n",
        "print(model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR8KXbLpyvaX",
        "outputId": "fcb23d55-82b7-40a3-f165-fd0819488ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with multi_class=\"ovr\": 0.97\n",
            "Model Coefficients:\n",
            "[[-4.70615403e-01  6.52347878e-01  1.15785115e+00 -5.93993010e-01\n",
            "  -2.40022883e-02  1.22893881e-01  1.34792635e+00  1.21129324e-01\n",
            "  -3.06785207e-01 -7.98211199e-02 -1.51671077e-01  7.16849518e-01\n",
            "   1.41153991e-02]\n",
            " [ 8.05008463e-01 -1.09848709e+00 -8.53071213e-01  2.77643511e-01\n",
            "   2.95994782e-03  6.31536994e-02  4.73150900e-01  2.72080075e-01\n",
            "   6.91066585e-01 -1.78399154e+00  6.66507852e-01  3.35794615e-01\n",
            "  -1.20384315e-02]\n",
            " [-2.59133933e-01  6.52310178e-01  1.20611740e-01  8.04321893e-02\n",
            "   1.92407496e-02 -5.19182381e-01 -1.70239118e+00 -1.24123949e-01\n",
            "  -7.08593522e-01  1.03220422e+00 -4.64782174e-01 -1.23780486e+00\n",
            "  -5.56613331e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
        "Regression. Print the best parameters and accuracy.\n",
        "'''"
      ],
      "metadata": {
        "id": "VVwQh2Ghyz3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Q1sauLSXzDlN",
        "outputId": "475c3ae0-18b4-4318-9f36-9c0a157c3bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da674b36-4019-4282-926a-c7389924f5d9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da674b36-4019-4282-926a-c7389924f5d9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "hCkvwtcn026_",
        "outputId": "1e3ad3e8-7901-4628-a79e-f65100b812b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  \n",
              "0        0         A/5 21171   7.2500   NaN        S  \n",
              "1        0          PC 17599  71.2833   C85        C  \n",
              "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3        0            113803  53.1000  C123        S  \n",
              "4        0            373450   8.0500   NaN        S  \n",
              "..     ...               ...      ...   ...      ...  \n",
              "886      0            211536  13.0000   NaN        S  \n",
              "887      0            112053  30.0000   B42        S  \n",
              "888      2        W./C. 6607  23.4500   NaN        S  \n",
              "889      0            111369  30.0000  C148        C  \n",
              "890      0            370376   7.7500   NaN        Q  \n",
              "\n",
              "[891 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95513fee-8f24-4a29-851f-d99b160badf7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95513fee-8f24-4a29-851f-d99b160badf7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95513fee-8f24-4a29-851f-d99b160badf7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95513fee-8f24-4a29-851f-d99b160badf7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-febeee0b-b4ab-47cf-9a40-e2bb230e5656\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-febeee0b-b4ab-47cf-9a40-e2bb230e5656')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-febeee0b-b4ab-47cf-9a40-e2bb230e5656 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c4528422-28c4-4b4e-9866-f3bd8b873db6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c4528422-28c4-4b4e-9866-f3bd8b873db6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334044,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.693428597180905,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that are not needed\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data.drop(columns=['Survived'])\n",
        "y = data['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xRjCirF1EAe",
        "outputId": "7b26a6a9-e587-4b26-dcae-169572018efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "average accuracy"
      ],
      "metadata": {
        "id": "cs-NCIcQ1KB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Define the Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate the model using Stratified K-Fold Cross-Validation\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print the average accuracy\n",
        "average_accuracy = np.mean(scores)\n",
        "print(f'Average Accuracy with Stratified K-Fold Cross-Validation: {average_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q-C3kZh1QZW",
        "outputId": "b62e7b45-fdad-47ca-cd99-351a53d44838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy with Stratified K-Fold Cross-Validation: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
        "accuracy."
      ],
      "metadata": {
        "id": "Zk-QVeGG1Wyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})  # Convert categorical to numerical\n",
        "\n",
        "df = df[features + ['Survived']].dropna()  # Drop rows with missing values\n",
        "\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch6aFZzS1bJ1",
        "outputId": "073c6c76-8e25-4618-b54e-e51401d7f385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy.\n",
        "'''"
      ],
      "metadata": {
        "id": "Ebb3py7B15ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# Preprocessing\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "# Drop columns that are not needed for the model\n",
        "df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
        "\n",
        "# Convert categorical 'Sex' to numerical\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Define features and target variable\n",
        "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "y = df['Survived']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': np.logspace(-4, 4, 40),  # Increased number of values for C\n",
        "    'penalty': ['l1', 'l2'],       # Regularization type\n",
        "    'solver': ['liblinear', 'saga']  # Solvers that support l1 and l2 penalties\n",
        "}\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
        "                                   n_iter=100, cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit RandomizedSearchCV\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "# Evaluate the model with the best parameters on the test set\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f'Best Parameters: {best_params}')\n",
        "print(f'Best Cross-Validation Score: {best_score:.4f}')\n",
        "print(f'Test Set Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx-PV82O17iw",
        "outputId": "aa729e85-336c-4eb2-990e-f8cd3e0addef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': np.float64(0.046415888336127774)}\n",
            "Best Cross-Validation Score: 0.7977\n",
            "Test Set Accuracy: 0.7989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Write a Python program to implement One-vs-One (Ovo) Multiclass Logistic Regression and print accuracy"
      ],
      "metadata": {
        "id": "JzAQbI0D2Ko_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply One-vs-One (Ovo) Multiclass Logistic Regression\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression(solver='liblinear'))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with One-vs-One (Ovo) Multiclass Logistic Regression: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy21aHKq2RIw",
        "outputId": "dade2050-45b9-4b10-a04f-6b6739302f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with One-vs-One (Ovo) Multiclass Logistic Regression: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification.\n",
        "'''"
      ],
      "metadata": {
        "id": "T9Hv7yUl2Xo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "1MMVQA-d2cgN",
        "outputId": "51a5ec05-810a-4b41-9572-6e5c31aaf09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.96\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score.\n",
        "'''"
      ],
      "metadata": {
        "id": "Rl_i0Wu52kNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Calculate and print Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-Score: {f1:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N_yfERn2nlT",
        "outputId": "7a32198e-07bd-4354-8e75-d33545ba0c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.99\n",
            "F1-Score: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance."
      ],
      "metadata": {
        "id": "44ADF9wX2vHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Generate an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with class weights to handle imbalanced data\n",
        "model = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Calculate and print Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-Score: {f1:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN_gFf1L2y3P",
        "outputId": "d5fa0e89-4958-4e91-cccf-edb9b2c604e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.86\n",
            "Precision: 0.41\n",
            "Recall: 0.75\n",
            "F1-Score: 0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance.\n",
        "'''"
      ],
      "metadata": {
        "id": "FCdPE_XF22um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Calculate and print Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-Score: {f1:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0rZAjkS27lF",
        "outputId": "fd23e3d2-c912-4fca-c197-36b36f119c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.81\n",
            "Precision: 0.79\n",
            "Recall: 0.74\n",
            "F1-Score: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling.\n",
        "'''"
      ],
      "metadata": {
        "id": "mUdPW_E_3C3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression(solver='liblinear')\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(f'Accuracy without scaling: {accuracy_no_scaling:.2f}')\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply Logistic Regression with scaling\n",
        "model_with_scaling = LogisticRegression(solver='liblinear')\n",
        "model_with_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "print(f'Accuracy with scaling: {accuracy_with_scaling:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATtFz4fq3Geh",
        "outputId": "b608f12c-a8f6-4789-a4df-56baed6ba36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.79\n",
            "Accuracy with scaling: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
        "'''"
      ],
      "metadata": {
        "id": "OX9j2EUi3LCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})  # Convert categorical to numerical\n",
        "\n",
        "df = df[features + ['Survived']].dropna()  # Drop rows with missing values\n",
        "\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Get probability scores for ROC-AUC\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFYg2t0F3PYo",
        "outputId": "1f414f50-0a32-4313-a6a2-7233e2c5982a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7483\n",
            "ROC-AUC Score: 0.8160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy."
      ],
      "metadata": {
        "id": "xyUxeqCs3cPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression with custom learning rate (C=0.5)\n",
        "model = LogisticRegression(C=0.5, solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with C=0.5: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8QRAutS3gXg",
        "outputId": "9fe8b4ee-e6e0-4fd7-f4ae-78ecbd2a8f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with C=0.5: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients."
      ],
      "metadata": {
        "id": "c0njYepo3lnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Identify important features based on model coefficients\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Coefficient': model.coef_[0]\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print('Important Features based on Model Coefficients:')\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5mQDlFF3p01",
        "outputId": "523ca6c1-a3cc-43ae-f503-19a966c9cbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Important Features based on Model Coefficients:\n",
            "    Feature  Coefficient\n",
            "1       Sex     2.595914\n",
            "5      Fare     0.003599\n",
            "2       Age    -0.025936\n",
            "4     Parch    -0.114953\n",
            "6  Embarked    -0.181170\n",
            "3     SibSp    -0.289865\n",
            "0    Pclass    -0.830931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa\n",
        "Score."
      ],
      "metadata": {
        "id": "7jn5v6A93vXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print Cohen's Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM48hngt3z9_",
        "outputId": "c94c5f0d-4c40-4339-b1a6-966b8787d679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classification.\n",
        "'''"
      ],
      "metadata": {
        "id": "8_XigqX834ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "average_precision = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, color='b', lw=2, label=f'Precision-Recall curve (area = {average_precision:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "kfwLOn_S39cR",
        "outputId": "15a3bc2e-def0-4c86-f7e1-063e3f8f52f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare\n",
        "their accuracy.\n",
        "'''"
      ],
      "metadata": {
        "id": "zn0LY9kd4Ezd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracy_results = {}\n",
        "\n",
        "# Train Logistic Regression with different solvers and compare accuracy\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=10000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_results[solver] = accuracy\n",
        "    print(f'Accuracy with solver {solver}: {accuracy:.2f}')\n",
        "\n",
        "# Print the results\n",
        "print('Comparison of solvers:')\n",
        "for solver, accuracy in accuracy_results.items():\n",
        "    print(f'Solver: {solver}, Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShGRUgfe4Jj7",
        "outputId": "ace811f6-0fe8-4333-e0ea-7d2d71793065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with solver liblinear: 0.79\n",
            "Accuracy with solver saga: 0.79\n",
            "Accuracy with solver lbfgs: 0.81\n",
            "Comparison of solvers:\n",
            "Solver: liblinear, Accuracy: 0.79\n",
            "Solver: saga, Accuracy: 0.79\n",
            "Solver: lbfgs, Accuracy: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "Correlation Coefficient (MCC)"
      ],
      "metadata": {
        "id": "aCPy0M8m4PVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnJbjvJZ4SoH",
        "outputId": "825c077e-6215-4581-8d1c-e83acffc6938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling.\n",
        "'''"
      ],
      "metadata": {
        "id": "ssTBAVIU4ZiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression(solver='liblinear')\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "print(f'Accuracy on raw data: {accuracy_raw:.2f}')\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression(solver='liblinear')\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f'Accuracy on standardized data: {accuracy_scaled:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-nd2Ixe4ecC",
        "outputId": "191cb27b-9315-43fa-f94f-66229732cb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 0.79\n",
            "Accuracy on standardized data: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
        "cross-validation.\n",
        "'''"
      ],
      "metadata": {
        "id": "GfKOu_HL4i35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Handle missing values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "# Prepare the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for C (regularization strength)\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Apply GridSearchCV to find the optimal C\n",
        "grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameter and accuracy\n",
        "print(f'Best C: {grid_search.best_params_[\"C\"]}')\n",
        "print(f'Best Cross-Validation Accuracy: {grid_search.best_score_:.2f}')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Set Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFS6L7ts4l46",
        "outputId": "4ea198b7-d288-4975-a6db-39433dd6d620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 1\n",
            "Best Cross-Validation Accuracy: 0.80\n",
            "Test Set Accuracy: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions."
      ],
      "metadata": {
        "id": "UUOolKWR4raF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})  # Convert categorical to numerical\n",
        "\n",
        "df = df[features + ['Survived']].dropna()  # Drop rows with missing values\n",
        "\n",
        "X = df[features]\n",
        "y = df['Survived']\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Apply Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, \"logistic_regression_model.pkl\")\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = joblib.load(\"logistic_regression_model.pkl\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_prob = loaded_model.predict_proba(X_test)[:, 1]  # Get probability scores for ROC-AUC\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkwH6zMF4v9Z",
        "outputId": "298830fd-10dd-4d79-c2b8-2ae7b7714c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7483\n",
            "ROC-AUC Score: 0.8160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WMIpgRu444O_"
      }
    }
  ]
}